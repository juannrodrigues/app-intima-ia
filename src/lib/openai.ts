import OpenAI from 'openai';

// Verifica se a API Key est√° configurada
if (!process.env.OPENAI_API_KEY) {
  console.error('‚ö†Ô∏è OPENAI_API_KEY n√£o est√° configurada no .env.local');
}

// Inicializa o cliente OpenAI
export const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

// Configura√ß√µes padr√£o
export const DEFAULT_MODEL = 'gpt-4o';
export const DEFAULT_TEMPERATURE = 0.8;
export const DEFAULT_MAX_TOKENS = 500;

// Tipos para as funcionalidades
export interface ChatCompletionParams {
  messages: Array<{
    role: 'system' | 'user' | 'assistant';
    content: string;
  }>;
  model?: string;
  temperature?: number;
  max_tokens?: number;
}

export interface ImageAnalysisParams {
  imageUrl: string;
  prompt?: string;
  model?: string;
}

export interface MessageGenerationParams {
  context: string;
  tone: string;
  intensity: string;
  language: string;
}

export interface ConversationAnalysisParams {
  messages: string[];
  analysisType: 'sentiment' | 'suggestions' | 'summary';
}

export interface FantasyModeParams {
  scenario: string;
  userInput: string;
  tone: string;
  intensity: string;
}

export interface GenerateMessagesParams {
  situation: string;
}

export interface GenerateFantasyParams {
  scenarioId: string;
  previousStory?: string;
  choice?: string;
  isPremium: boolean;
  isFirstSegment: boolean;
}

// Fun√ß√£o para chat com a IA
export async function chatWithAI(params: ChatCompletionParams) {
  try {
    if (!process.env.OPENAI_API_KEY) {
      throw new Error('API Key da OpenAI n√£o configurada');
    }

    console.log('ü§ñ Chamando OpenAI API...');

    const response = await openai.chat.completions.create({
      model: params.model || DEFAULT_MODEL,
      messages: params.messages,
      temperature: params.temperature || DEFAULT_TEMPERATURE,
      max_tokens: params.max_tokens || DEFAULT_MAX_TOKENS,
    });

    const messageContent = response.choices[0]?.message?.content;

    if (!messageContent) {
      throw new Error('Resposta vazia da OpenAI');
    }

    console.log('‚úÖ Resposta recebida da OpenAI');

    return {
      success: true,
      message: messageContent,
      usage: response.usage,
    };
  } catch (error: any) {
    console.error('‚ùå Erro ao chamar OpenAI:', error);
    console.error('üìã Detalhes do erro:', error?.message, error?.status);

    // Tratamento espec√≠fico de erros da OpenAI
    if (error?.status === 401) {
      return {
        success: false,
        message: '',
        error: 'Erro de autentica√ß√£o. Verifique sua API Key da OpenAI.',
      };
    }

    if (error?.status === 429) {
      return {
        success: false,
        message: '',
        error: 'Limite de requisi√ß√µes atingido. Tente novamente em alguns instantes.',
      };
    }

    if (error?.status === 500) {
      return {
        success: false,
        message: '',
        error: 'Erro no servidor da OpenAI. Tente novamente.',
      };
    }

    if (error?.code === 'ENOTFOUND' || error?.code === 'ECONNREFUSED') {
      return {
        success: false,
        message: '',
        error: 'Erro de conex√£o com a OpenAI. Verifique sua internet.',
      };
    }

    return {
      success: false,
      message: '',
      error: error instanceof Error ? error.message : 'Erro desconhecido ao processar sua mensagem',
    };
  }
}

// Fun√ß√£o para analisar imagens
export async function analyzeImage(params: ImageAnalysisParams) {
  try {
    if (!process.env.OPENAI_API_KEY) {
      throw new Error('API Key da OpenAI n√£o configurada');
    }

    const response = await openai.chat.completions.create({
      model: params.model || 'gpt-4o',
      messages: [
        {
          role: 'user',
          content: [
            {
              type: 'text',
              text:
                params.prompt ||
                'Analise esta imagem e descreva o que voc√™ v√™ de forma detalhada e sensual, mantendo o respeito.',
            },
            {
              type: 'image_url',
              image_url: {
                url: params.imageUrl,
              },
            },
          ],
        },
      ],
      max_tokens: 500,
    });

    return {
      success: true,
      analysis: response.choices[0]?.message?.content || '',
    };
  } catch (error: any) {
    console.error('Erro ao analisar imagem:', error);
    return {
      success: false,
      analysis: 'N√£o foi poss√≠vel analisar a imagem.',
      error: error instanceof Error ? error.message : 'Erro desconhecido',
    };
  }
}

// Fun√ß√£o para gerar mensagens prontas
export async function generateReadyMessage(params: MessageGenerationParams) {
  try {
    if (!process.env.OPENAI_API_KEY) {
      throw new Error('API Key da OpenAI n√£o configurada');
    }

    const systemPrompt = `Voc√™ √© um assistente especializado em criar mensagens ${params.tone} com intensidade ${params.intensity}. 
Crie mensagens criativas, envolventes e personalizadas em ${params.language}.`;

    const response = await openai.chat.completions.create({
      model: DEFAULT_MODEL,
      messages: [
        { role: 'system', content: systemPrompt },
        {
          role: 'user',
          content: `Crie uma mensagem baseada neste contexto: ${params.context}`,
        },
      ],
      temperature: 0.9,
      max_tokens: 200,
    });

    return {
      success: true,
      message: response.choices[0]?.message?.content || '',
    };
  } catch (error: any) {
    console.error('Erro ao gerar mensagem:', error);
    return {
      success: false,
      message: 'N√£o foi poss√≠vel gerar a mensagem.',
      error: error instanceof Error ? error.message : 'Erro desconhecido',
    };
  }
}

// Fun√ß√£o para gerar m√∫ltiplas mensagens para uma situa√ß√£o
export async function generateMessagesForSituation(params: GenerateMessagesParams) {
  try {
    if (!process.env.OPENAI_API_KEY) {
      throw new Error('API Key da OpenAI n√£o configurada');
    }

    console.log('üìù Gerando mensagens para situa√ß√£o:', params.situation);

    const systemPrompt = `Voc√™ √© um especialista em comunica√ß√£o rom√¢ntica e social, inclusivo para todos os g√™neros e orienta√ß√µes.
Sua miss√£o √© criar mensagens aut√™nticas, criativas e adequadas para qualquer tipo de relacionamento.

IMPORTANTE:
- Seja inclusivo: adapte a linguagem para qualquer g√™nero/orienta√ß√£o
- Crie mensagens naturais, n√£o robotizadas
- Varie o tom: pode ser fofo, ousado, engra√ßado, rom√¢ntico, etc
- Mensagens CURTAS (m√°ximo 2-3 linhas cada)
- Evite clich√™s √≥bvios
- Seja aut√™ntico e moderno

Retorne APENAS um objeto JSON v√°lido com este formato exato (sem markdown, sem explica√ß√µes):
{"messages": ["mensagem 1", "mensagem 2", "mensagem 3"]}`;

    const userPrompt = `Situa√ß√£o: ${params.situation}

Gere 3 op√ß√µes de mensagens curtas e criativas para essa situa√ß√£o. Retorne APENAS o JSON.`;

    const response = await openai.chat.completions.create({
      model: DEFAULT_MODEL,
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: userPrompt },
      ],
      temperature: 0.9,
      max_tokens: 500,
      response_format: { type: 'json_object' },
    });

    const responseText = response.choices[0]?.message?.content;

    if (!responseText) {
      throw new Error('Resposta vazia da OpenAI');
    }

    console.log('‚úÖ Resposta recebida da OpenAI');

    // Limpa a resposta
    let cleanedResponse = responseText.trim();
    if (cleanedResponse.startsWith('```json')) {
      cleanedResponse = cleanedResponse.replace(/```json\n?/g, '').replace(/```\n?/g, '');
    } else if (cleanedResponse.startsWith('```')) {
      cleanedResponse = cleanedResponse.replace(/```\n?/g, '');
    }
    cleanedResponse = cleanedResponse.trim();

    console.log('üßπ Resposta limpa');

    // Parse do JSON
    let parsedResponse;
    try {
      parsedResponse = JSON.parse(cleanedResponse);
    } catch (parseError: any) {
      console.error('‚ùå Erro ao fazer parse do JSON:', parseError);
      console.error('üìÑ Conte√∫do que falhou:', cleanedResponse);

      // Fallback: tenta extrair mensagens manualmente
      const messageMatches = cleanedResponse.match(/"([^"]+)"/g);
      if (messageMatches && messageMatches.length >= 3) {
        const extractedMessages = messageMatches
          .slice(0, 3)
          .map(m => m.replace(/"/g, ''));

        console.log('‚úÖ Mensagens extra√≠das manualmente:', extractedMessages);

        return {
          success: true,
          messages: extractedMessages,
          usage: response.usage,
        };
      }

      throw new Error(`Formato de resposta inv√°lido: ${parseError.message}`);
    }

    if (!parsedResponse.messages || !Array.isArray(parsedResponse.messages)) {
      console.error('‚ùå Formato inv√°lido:', parsedResponse);
      throw new Error('Formato de resposta inv√°lido - esperado array de mensagens');
    }

    // Garante que temos exatamente 3 mensagens
    const messages = parsedResponse.messages.slice(0, 3);

    if (messages.length === 0) {
      throw new Error('Nenhuma mensagem foi gerada');
    }

    console.log('‚úÖ Mensagens geradas com sucesso!', messages);

    return {
      success: true,
      messages,
      usage: response.usage,
    };
  } catch (error: any) {
    console.error('‚ùå Erro ao gerar mensagens:', error);
    return {
      success: false,
      messages: [],
      error: error instanceof Error ? error.message : 'Erro desconhecido',
    };
  }
}

// Fun√ß√£o para analisar conversas
export async function analyzeConversation(params: ConversationAnalysisParams) {
  try {
    if (!process.env.OPENAI_API_KEY) {
      throw new Error('API Key da OpenAI n√£o configurada');
    }

    const analysisPrompts = {
      sentiment:
        'Analise o sentimento geral desta conversa e forne√ßa insights sobre o tom emocional.',
      suggestions:
        'Analise esta conversa e forne√ßa sugest√µes de como melhorar a comunica√ß√£o e criar mais conex√£o.',
      summary: 'Fa√ßa um resumo desta conversa destacando os pontos principais.',
    };

    const conversationText = params.messages.join('\n\n');

    const response = await openai.chat.completions.create({
      model: DEFAULT_MODEL,
      messages: [
        {
          role: 'system',
          content:
            'Voc√™ √© um especialista em an√°lise de conversas rom√¢nticas e relacionamentos.',
        },
        {
          role: 'user',
          content: `${analysisPrompts[params.analysisType]}\n\nConversa:\n${conversationText}`,
        },
      ],
      temperature: 0.7,
      max_tokens: 600,
    });

    return {
      success: true,
      analysis: response.choices[0]?.message?.content || '',
    };
  } catch (error: any) {
    console.error('Erro ao analisar conversa:', error);
    return {
      success: false,
      analysis: 'N√£o foi poss√≠vel analisar a conversa.',
      error: error instanceof Error ? error.message : 'Erro desconhecido',
    };
  }
}

// Fun√ß√£o para gerar hist√≥rias de fantasia interativas
export async function generateFantasyStory(params: GenerateFantasyParams) {
  try {
    if (!process.env.OPENAI_API_KEY) {
      throw new Error('API Key da OpenAI n√£o configurada');
    }

    const scenarioPrompts: Record<string, string> = {
      car: 'um encontro √≠ntimo e apaixonado dentro de um carro estacionado em um lugar privado e rom√¢ntico',
      hotel: 'uma noite luxuosa e sensual em um quarto de hotel sofisticado com champanhe e atmosfera rom√¢ntica',
      distance: 'uma conex√£o intensa e provocante atrav√©s de mensagens e chamadas √† dist√¢ncia',
      beach: 'um encontro rom√¢ntico e apaixonado em uma praia deserta sob o luar',
      home: 'um momento √≠ntimo e confort√°vel em casa, sem pressa, explorando a conex√£o',
      surprise: 'um encontro inesperado e surpreendente que transforma a rela√ß√£o'
    };

    const scenarioDescription = scenarioPrompts[params.scenarioId] || scenarioPrompts.car;
    console.log('‚úÖ Gerando hist√≥ria para cen√°rio:', params.scenarioId);

    let prompt = '';

    if (params.isFirstSegment) {
      // Primeira cena
      if (params.isPremium) {
        prompt = `Crie o in√≠cio de uma hist√≥ria interativa rom√¢ntica e sensual sobre ${scenarioDescription}.

IMPORTANTE:
- Escreva em portugu√™s brasileiro
- Use linguagem elegante, sugestiva mas n√£o expl√≠cita
- Crie tens√£o e qu√≠mica entre os personagens
- Seja inclusivo quanto a g√™neros e orienta√ß√µes
- Termine em um ponto de escolha interessante
- A hist√≥ria deve ter aproximadamente 200-250 palavras

Retorne APENAS um objeto JSON v√°lido com este formato exato (sem markdown, sem explica√ß√µes):
{
  "text": "texto da hist√≥ria aqui",
  "choices": ["Op√ß√£o 1", "Op√ß√£o 2", "Op√ß√£o 3"]
}`;
      } else {
        // Vers√£o free - cena curta e completa
        prompt = `Crie uma cena curta, completa e envolvente sobre ${scenarioDescription}.

IMPORTANTE:
- Escreva em portugu√™s brasileiro
- Use linguagem elegante, sugestiva mas n√£o expl√≠cita
- Crie tens√£o e qu√≠mica entre os personagens
- Seja inclusivo quanto a g√™neros e orienta√ß√µes
- A cena deve ser completa (in√≠cio, meio e fim satisfat√≥rio)
- Aproximadamente 150-180 palavras
- N√ÉO inclua escolhas (√© uma cena √∫nica do plano free)

Retorne APENAS um objeto JSON v√°lido com este formato exato (sem markdown, sem explica√ß√µes):
{
  "text": "texto da hist√≥ria completa aqui",
  "choices": []
}`;
      }
    } else {
      // Continua√ß√£o da hist√≥ria (apenas Premium)
      prompt = `Continue esta hist√≥ria interativa baseada na escolha do usu√°rio.

HIST√ìRIA ANTERIOR:
${params.previousStory}

ESCOLHA DO USU√ÅRIO: ${params.choice}

IMPORTANTE:
- Continue naturalmente a partir da escolha
- Mantenha o tom rom√¢ntico e sensual
- Desenvolva a tens√£o e qu√≠mica
- Seja inclusivo quanto a g√™neros e orienta√ß√µes
- Termine em um novo ponto de escolha
- Aproximadamente 200-250 palavras

Retorne APENAS um objeto JSON v√°lido com este formato exato (sem markdown, sem explica√ß√µes):
{
  "text": "continua√ß√£o da hist√≥ria aqui",
  "choices": ["Op√ß√£o 1", "Op√ß√£o 2", "Op√ß√£o 3"]
}`;
    }

    const response = await openai.chat.completions.create({
      model: DEFAULT_MODEL,
      messages: [
        {
          role: 'system',
          content: 'Voc√™ √© um escritor especializado em hist√≥rias rom√¢nticas e sensuais interativas. Suas hist√≥rias s√£o elegantes, envolventes e respeitosas, criando tens√£o e qu√≠mica sem ser expl√≠cito. Voc√™ sempre responde em JSON v√°lido sem markdown.'
        },
        {
          role: 'user',
          content: prompt
        }
      ],
      response_format: { type: 'json_object' },
      temperature: 0.8,
    });

    const responseText = response.choices[0]?.message?.content;

    if (!responseText) {
      throw new Error('Resposta vazia da OpenAI');
    }

    console.log('‚úÖ Resposta recebida da OpenAI');

    // Limpa a resposta
    let cleanedResponse = responseText.trim();
    if (cleanedResponse.startsWith('```json')) {
      cleanedResponse = cleanedResponse.replace(/```json\n?/g, '').replace(/```\n?/g, '');
    } else if (cleanedResponse.startsWith('```')) {
      cleanedResponse = cleanedResponse.replace(/```\n?/g, '');
    }
    cleanedResponse = cleanedResponse.trim();

    console.log('üßπ Resposta limpa');

    // Parse do JSON
    let story;
    try {
      story = JSON.parse(cleanedResponse);
    } catch (parseError: any) {
      console.error('‚ùå Erro ao fazer parse do JSON:', parseError);
      console.error('üìÑ Conte√∫do que falhou:', cleanedResponse);

      // Fallback
      story = {
        text: 'Desculpe, houve um erro ao gerar a hist√≥ria. Por favor, tente novamente.',
        choices: []
      };
    }

    // Valida estrutura
    if (!story.text) {
      console.error('‚ùå Formato inv√°lido: falta campo "text"');
      story.text = 'Erro ao gerar hist√≥ria. Tente novamente.';
    }

    if (!Array.isArray(story.choices)) {
      console.warn('‚ö†Ô∏è Campo "choices" n√£o √© array, corrigindo...');
      story.choices = [];
    }

    console.log('‚úÖ Hist√≥ria gerada com sucesso!');

    return {
      success: true,
      story,
      usage: response.usage,
    };
  } catch (error: any) {
    console.error('‚ùå Erro ao gerar hist√≥ria:', error);
    return {
      success: false,
      story: {
        text: 'Erro ao gerar hist√≥ria. Tente novamente.',
        choices: []
      },
      error: error instanceof Error ? error.message : 'Erro desconhecido',
    };
  }
}

// Fun√ß√£o para Modo Fantasia (roleplay guiado)
export async function fantasyMode(params: FantasyModeParams) {
  try {
    if (!process.env.OPENAI_API_KEY) {
      throw new Error('API Key da OpenAI n√£o configurada');
    }

    const systemPrompt = `Voc√™ est√° no Modo Fantasia, criando uma experi√™ncia de roleplay ${params.tone} com intensidade ${params.intensity}.
Seja criativo, envolvente e mantenha a narrativa fluindo naturalmente.
Cen√°rio: ${params.scenario}`;

    const response = await openai.chat.completions.create({
      model: DEFAULT_MODEL,
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: params.userInput },
      ],
      temperature: 0.9,
      max_tokens: 600,
    });

    return {
      success: true,
      response: response.choices[0]?.message?.content || '',
    };
  } catch (error: any) {
    console.error('Erro no Modo Fantasia:', error);
    return {
      success: false,
      response: 'N√£o foi poss√≠vel continuar a fantasia.',
      error: error instanceof Error ? error.message : 'Erro desconhecido',
    };
  }
}